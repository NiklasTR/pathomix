import numpy as np
import pandas as pd
import os
import random
import shutil
from keras.utils import Sequence, to_categorical
import imageio


class DataLoader(Sequence):

    def __init__(self, data_frame, data_dir, batch_size, dim=(456,456), n_channels=3, shuffle=True):
        self.data_frame = data_frame
        self.list_IDs = list(self.data_frame.index)
        self.labels = to_categorical(self.data_frame['num_label'])
        self.n_classes = len(self.data_frame['label'].unique())
        self.dim = dim
        self.n_channels = n_channels
        self.batch_size = batch_size
        self.shuffle = shuffle
        self.data_dir = data_dir
        self.load_data_set()
        self.on_epoch_end()

    def load_data_set(self):
        data_list = []
        for fp in self.data_frame['relative_path']:
            file_path = os.path.join(self.data_dir, fp)
            # cut to relevant size
            file = imageio.imread(file_path)[:self.dim[0],:self.dim[1]]
            data_list.append(file)
        self.data = np.array(data_list)


    def on_epoch_end(self):
        'Updates indexes after each epoch'
        self.indexes = np.arange(len(self.list_IDs))
        if self.shuffle == True:
            np.random.shuffle(self.indexes)

    def __len__(self):
        return int(np.ceil(len(self.list_IDs) / float(self.batch_size)))

    def __getitem__(self, index):
        'Generate one batch of data'
        # Generate indexes of the batch
        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]

        # Generate data
        X, y = self.__data_generation(indexes)

        return X, y

    def __data_generation(self, indexes):
        'Generates data containing batch_size samples'  # X : (n_samples, *dim, n_channels)
        # Initialization
        X = np.empty((self.batch_size, *self.dim, self.n_channels))
        y = np.empty((self.batch_size, self.n_classes), dtype=int)

        # Generate data
        for idx, ID in enumerate(indexes):
            # Store sample
            X[idx,] = self.data[ID]

            # Store class
            y[idx,] = self.labels[ID]

        return X, y

def create_data_frame(base_dir):
    data_list = []
    for root, dirs, files in os.walk(base_dir):
        for file in files:
            if file.endswith('.png'):
                dir_name = os.path.basename(root)
                relative_path = os.path.join('.', dir_name, file)
                data_list.append({"relative_path": relative_path, "label": os.path.basename(root)})
    data_frame = pd.DataFrame(data_list)
    data_frame.loc[:, ('num_label')] = data_frame.label.astype('category').cat.codes
    return data_frame


def split_data_frame(df, train_idx, val_idx):
    df_train = df.iloc[train_idx]
    df_val = df.iloc[val_idx]
    return df_train, df_val


def list_all_files_for_class(base_dir, label):
    list_of_files = []
    for root, dirs, files in os.walk(base_dir):
        for file in files:
            if not label in root:
                break
            if file.endswith('.png'):
                dir_name = os.path.basename(root)
                list_of_files.append(os.path.join(dir_name, file))
    return list_of_files


def pick_random_sample(file_list, proportion=0.2):
    pick_n = int(len(file_list) * proportion)
    return random.sample(file_list, pick_n)


def move_files(file_list, source_dir, target_dir, label):
    target_folder = os.path.join(target_dir, label)
    if not os.path.exists(target_folder):
        os.mkdir(target_folder)
    for f in file_list:
        source_path = os.path.join(source_dir, f)
        target_path = os.path.join(target_dir, f)
        shutil.move(source_path, target_path)


def create_test_set(base_dir=os.path.join(os.environ['PATHOMIX_DATA'], 'Jakob_cancer_detection', 'train')):
    labels = ['ADIMUC', 'STRMUS', 'TUMSTU']
    source_dir = '/home/pmf/Documents/DataMining/datasets/pathology/Jakob_cancer_detection/train'
    target_dir = '/home/pmf/Documents/DataMining/datasets/pathology/Jakob_cancer_detection/test'

    for l in labels:
        total_list = list_all_files_for_class(base_dir, l)
        random_list = pick_random_sample(total_list, proportion=0.2)
        move_files(random_list, source_dir, target_dir, l)

def random_crop(img, random_crop_size=(456,456)):
    # Note: image_data_format is 'channel_last'
    assert img.shape[2] == 3
    height, width = img.shape[0], img.shape[1]
    dy, dx = random_crop_size
    x = np.random.randint(0, width - dx + 1)
    y = np.random.randint(0, height - dy + 1)
    return img[y:(y+dy), x:(x+dx), :]


def crop_generator(batches, crop_length):
    """Take as input a Keras ImageGen (Iterator) and generate random
    crops from the image batches generated by the original iterator.
    """
    while True:
        batch_x, batch_y = next(batches)
        batch_crops = np.zeros((batch_x.shape[0], crop_length, crop_length, 3))
        for i in range(batch_x.shape[0]):
            batch_crops[i] = random_crop(batch_x[i], (crop_length, crop_length))
        yield (batch_crops, batch_y)